{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPegpHlDOfptB1WUaff19cj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishantgovil03/LJMUResearch/blob/main/BiDirectionalLSTM_AdamOptimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIAayE71-fpL"
      },
      "source": [
        "The source code for text Summarization using Bidirectional LSTM\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtTgT-bWKVKu",
        "outputId": "7156108d-ffc0-442c-c747-e8d7f0097690"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hCTwA3b4us9"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzasM2VyKl0L",
        "outputId": "991f0cd2-92e9-4c1a-d092-e770a6f92940"
      },
      "source": [
        "%cd drive/MyDrive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbGjzCxj8Abr"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4IzDMuKpOe"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import re\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "from keras.preprocessing.text import Tokenizer \r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from tensorflow.keras.layers import Input, LSTM , Bidirectional\r\n",
        "from tensorflow.keras.layers import  Embedding, Dense, Concatenate, TimeDistributed\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "import warnings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWS9YBDs8EXF"
      },
      "source": [
        "Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNcux6uIKswR"
      },
      "source": [
        "data = pd.read_csv(\"InputData.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB-Hdlql8Hys"
      },
      "source": [
        "Data Pre-processing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egeVM5KmKuoD",
        "outputId": "22803b07-ebe1-45c8-ee39-dfc4ec42f523"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4450 entries, 0 to 4449\n",
            "Data columns (total 4 columns):\n",
            " #   Column                       Non-Null Count  Dtype \n",
            "---  ------                       --------------  ----- \n",
            " 0   Unnamed: 0                   4450 non-null   int64 \n",
            " 1   Articles without stop words  4450 non-null   object\n",
            " 2   Article with stop words      4450 non-null   object\n",
            " 3   Summary                      4450 non-null   object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 139.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuRuTG_zMTOl",
        "outputId": "62f85f82-bc57-456f-c61c-ea8be3968c9c"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4rsfuEkMjfs"
      },
      "source": [
        "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\r\n",
        "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\r\n",
        "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\r\n",
        "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\r\n",
        "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\r\n",
        "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\r\n",
        "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\r\n",
        "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\r\n",
        "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\r\n",
        "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\r\n",
        "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\r\n",
        "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\r\n",
        "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\r\n",
        "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\r\n",
        "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\r\n",
        "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\r\n",
        "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\r\n",
        "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\r\n",
        "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\r\n",
        "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\r\n",
        "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\r\n",
        "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\r\n",
        "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DODdyK8HMNuy"
      },
      "source": [
        "stop_words=set(stopwords.words('english'))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UquVmNzn8NIy"
      },
      "source": [
        "Data Cleaner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyLPLMfRLtpa"
      },
      "source": [
        "def text_cleaner(text,num):\r\n",
        "    newString = text.lower()\r\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\r\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\r\n",
        "    newString = re.sub('\"','', newString)\r\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \r\n",
        "    newString = re.sub(r\"'s\\b\",\"\",newString)\r\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \r\n",
        "    newString = re.sub('[m]{2,}', 'mm', newString)\r\n",
        "    if(num==0):\r\n",
        "        tokens = [w for w in newString.split() if not w in stop_words]\r\n",
        "    else:\r\n",
        "        tokens=newString.split()\r\n",
        "    long_words=[]\r\n",
        "    for i in tokens:\r\n",
        "        if len(i)>1:                                                 #removing short word\r\n",
        "            long_words.append(i)   \r\n",
        "    return (\" \".join(long_words)).strip()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOAYwhfAMq2P"
      },
      "source": [
        "#call the function\r\n",
        "cleaned_text = []\r\n",
        "for t in data['Article with stop words']:\r\n",
        "    cleaned_text.append(text_cleaner(t,0))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvKyTwNnM3PN",
        "outputId": "912f11cc-3eeb-4ff8-8e36-d0f54e5c9b89"
      },
      "source": [
        "cleaned_text[:5]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['budget set scene electiongordon brown seek put economy centre labour bid third term power delivers ninth budget expected stress importance continued economic low unemployment interest chancellor expected freeze petrol duty raise stamp duty threshold conservatives lib dems insist voters face higher taxes officials said mr brown thought increase stamp duty threshold freeze petrol duty extension tax credit scheme poorer families possible help pensioners stamp duty threshold rise intended help first time buyers likely theme three main general election ten years buyers much greater chance avoiding stamp close half million england wales selling less since average uk property prices doubled starting threshold stamp duty tax credits number properties incurring stamp duty rocketed government tax liberal democrats unveiled proposals raise stamp duty threshold tories also thought likely propose increased shadow chancellor oliver letwin branding stamp duty classic labour stealth tories say whatever chancellor gives away clawed back higher taxes labour returned shadow treasury chief secretary george osborne everyone looks british economy moment says sharp deterioration public black labour elected substantial tax increase budget order around mr brown former advisor ed parliamentary said examination tory plans economy showed would difference investment end next parliament two main accept need changes plans set meet spending lib dems david laws chancellor doubt tell us today wonderfully economy lot built increase personal consumer debt last years makes economy quite vulnerable potentially interest rates ever go significant snp leader alex salmond said party would introduce grant first time reduce corporation tax introduce citizens pension free means plaid cymru economics spokesman adam price said wanted help get people housing ladder increase minimum wage',\n",
              " 'army chiefs regiments decisionmilitary chiefs expected meet make final decision future scotland army committee army made senior defence discuss plans restructuring regiments proposals include cutting scotland six regiments five merging super plans faced stiff opposition campaigners politicians committee decision must ratified defence secretary geoff hoon prime minister tony expected made public next ministers announced reorganisation army drew question mark futures black kings scottish royal royal highland fusiliers argyll sutherland council scottish colonels proposed merger royal scots king scottish borderers single would one five new super proposals either merge amalgamate six regiments super regiment sparked political labour backbenchers opposition politicians opposing felt timing insensitive black watch frontline suffering save scottish regiments campaigners angered threatened stand labour next general ahead expected army board spokesman government army board spent past four months attempting trick serving soldiers public thinking planned changes scottish regiments good army serving much good destroy scotland regiments moulding single super regiment lead severe recruitment loss local connections regiments loss scotland important part heritage future regiments envy armies around alternative blueprint put forward labour mp eric proposed going ahead merger preserving brief speculation prime minister might consider seems speaking scotland last mr blair said aim preserve tradition introduce effective structure hinted super regiment want get rid history traditions regiment local connections far want make sure transfer people easily across regiments deploy prime minister said hoped concerns would taken account need effective change',\n",
              " 'howard denies split id cardsmichael howard denied shadow cabinet split decision back controversial labour plans introduce id tory leader said front bench team reached collective view holding good admitted easy decided support plans police said would help fight crime illegal lib dems pledged oppose bill debated next sources say senior party figures argued vociferously id card among reported serious reservations strategy senior shadow cabinet members david oliver letwin tim mr howard denied mr transport environment said plans also said confident shadow home secretary mr davis would set position clearly stands debate matter next mr howard said police said id cards could help foil terror bomb plot people could lose police say take acknowledged good libertarian arguments said shadow cabinet weighed conflicting interests reaching pretend easy decision end day decision also denied afraid looking soft compared conservatives announced support government plans monday within party told bbc mr howard always favour id tried introduce home tories insisted would hold ministers account precise purpose said would also press labour whether objectives could met whether home office would able deliver pledged assess cost effectiveness id cards whether people privacy would properly important remember bill take decade come full spokesman lib dem home affairs spokesman mark oaten branded id scheme waste money deeply signs michael howard overruling concerns id chairman bar guy mansfield qc warned real risk people margins society would driven hands going happen young asian men bomb gone going going tory douglas hogg said opposed plans id cards branding regressive step would intrude lives ordinary citizens without counterbalancing predicted ultimately carrying cards would become compulsory would lead large numbers britain ethnic minorities stopped',\n",
              " 'observers monitor uk electionministers invite international observers check forthcoming uk general election fairly move comes amid claims poll could marred electoral report two mps committees called thursday urgent changes electoral registration system combat vote rigging boost written response labour mp gordon government said would normally invite observers uk constitutional affairs minister christopher leslie fully expect us repeat previous practice date next general election government looked ways boosting voter fell last general election trial ballots four english regions last summer hit delays fraud liberal democrat peer lord greaves called last week international observers general election saying otherwise could months court challenges scale seen since thursday report drawn two committees scrutinising work office deputy prime minister said growth postal strong case tighten fraud protection requiring voters register rather also said three million people eligible vote registered general election suggest people aged black voters electoral young people shared accommodation thought miss one acts head household fill odpm committee chairman andrew bennett said individual voter opposed registration quickly introduced could dramatically reduce chances counterpart dca alan said delayed measures likely increase registration put place proved shadow constitutional affairs secretary oliver heald accused government dragging feet badly needed vital move ahead northern ireland system individual electoral registration safeguard integrity britain electoral report said individual registration treated carefully voters disappeared electoral roll northern ireland introduced report said government consider fines unregistered accepted many experts said would expensive system would hard said incentives council tax likely seen gimmicks risked undermining integrity mps instead called imaginative campaigns boost',\n",
              " 'kilroy names election seat show host robert contest derbyshire seat erewash next general elizabeth blackman seat says fight record constituency mr announced plans day launching new latin east midlands quit uk independence wants new group change face uk choice election constituency quashes speculation would stand defence secretary geoff hoon ukip vote erewash last june european elections mr among candidates erewash held tories since ms blackman said proud government achievements declined give view mr told london news conference veritas would avoid old lies said country stolen us mass immigration promised firm fair policy veritas says hopes contest seats forthcoming general election plans announce detailed policies health defence next leader roger knapman says glad see back mr labour campaign spokesman fraser kemp said veritas joining already crowded field right british mr joined new venture one ukip two london assembly damien deputy chairman petrina holdsworth said group parody party men mr quit ukip last week months tension vied unsuccessfully leadership said ashamed member ukip whose leadership gone awol great opportunity offered third place last june european ukip roger said glad see back mr remarkable ability influence people election became clear interested robert party uk independence party nice knowing ukip officials also argue mr straightforward attacking party wanted']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33AiSarnNDYN"
      },
      "source": [
        "cleaned_summary = []\r\n",
        "for t in data['Summary']:\r\n",
        "    cleaned_summary.append(text_cleaner(t,1))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWGrYB6LQNUV"
      },
      "source": [
        "data['cleaned_text']=cleaned_text\r\n",
        "data['cleaned_summary']=cleaned_summary"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NInjwAG5NZ69",
        "outputId": "0602d593-6a29-44b5-b373-efb222538b7d"
      },
      "source": [
        "cleaned_summary[:10]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['increase in the stamp duty threshold from freeze on petrol duty an extension of tax credit scheme for poorer families possible help for pensioners the stamp duty threshold rise is intended to help first time buyers likely theme of all three of the main general election chancellor is expected to freeze petrol duty and raise the stamp duty threshold from tories are also thought likely to propose increased with shadow chancellor oliver letwin branding stamp duty classic labour stealth credits as the number of properties incurring stamp duty has rocketed as has the government tax average uk property prices have more than doubled while the starting threshold for stamp duty has not the lib dems david laws the chancellor will no doubt tell us today how wonderfully the economy is he liberal democrats unveiled their own proposals to raise the stamp duty threshold to in labour is elected there will be very substantial tax increase in the budget after the of the order of around',\n",
              " 'they are very much not for the good and will destroy scotland regiments by moulding them into single super regiment which will lead to severe recruitment loss of local connections to those regiments and loss to scotland of an important part of her heritage most her future the regiments are the envy of armies around the proposals to either merge or amalgamate the six regiments into super regiment sparked political with labour backbenchers and opposition politicians opposing the proposals include cutting scotland six regiments to five and merging these into super in scotland last mr blair said the aim was to preserve tradition but introduce more effective structure and hinted that super regiment was committee of the army which is made up of the most senior defence will discuss plans for restructuring regiments on ahead of the expected army board spokesman the government and the army board have spent the past four months attempting to trick serving soldiers and the public into thinking their planned changes for the scottish regiments are for the good of the army and for that of the serving their it would be one of five in the new super they do not want to get rid of the history or the traditions of the regiment or the local connections far from all they want to do is make sure they can transfer people easily across regiments and deploy them more',\n",
              " 'michael howard has denied his shadow cabinet was split over its decision to back controversial labour plans to introduce id howard said the police had said id cards could help them foil terror bomb plot in which people could lose their this has all the signs of michael howard overruling concerns over id also said he was confident shadow home secretary mr davis would set out the position very clearly when he stands up to debate the matter next had decided to support the plans as the police said they would help fight crime and illegal douglas hogg said he opposed the plans for id cards branding them regressive step which would intrude into the lives of ordinary citizens without any counterbalancing said they would also press labour over whether objectives could be met and whether the home office would be able to deliver mr howard denied mr his transport and environment said the plans within the party told the bbc mr howard had always been in favour of id and tried to introduce them when he was home they have not they are going to be they pledged to assess the cost effectiveness of id cards and whether people privacy would be properly',\n",
              " 'the report said individual registration should be treated carefully as of voters disappeared from the electoral roll in northern ireland when it was introduced in committee chairman andrew bennett said individual voter as opposed to registration by should be quickly introduced as it could dramatically reduce the chances of is vital that we move ahead with the northern ireland system of individual electoral registration to safeguard the integrity of the britain electoral he report by two mps committees called on thursday for urgent changes to the electoral registration system to combat vote rigging and boost for the general election suggest of people aged between and and of black voters were not on the electoral report said the government should consider fines for unregistered but accepted many experts said it would be an expensive system that would be hard to in written response to labour mp gordon the government said it would normally invite observers to any uk said incentives to such as council tax were likely to be seen as gimmicks and risked undermining the integrity of the mps government has looked at ways of boosting voter which fell to in the last general election in',\n",
              " 'ukip roger has said he is glad to see the back of mr has remarkable ability to influence people after the election it became clear that he was more interested in the robert party than the uk independence party so it was nice knowing now he leader roger knapman says he is glad to see the back of mr won of the vote in erewash in last june european elections with mr among their candidates for the officials also argue mr has not been straightforward in attacking the party he once wanted to announced his plans day after launching his new the latin for quit ukip last week after months of tension as he vied unsuccessfully for the leadership of that was joined in the new venture by one of ukip two london assembly damien who is now deputy show host robert is to contest the derbyshire seat of erewash at the next general',\n",
              " 'mr bannatyne has previously given labour bannatyne disunity in the cabinet has corrosive effect on the warned the abstentions party was the real challenge to labour and they would not be motivated by mr blair promise to produce an unremittingly new labour election he insisted the recent squabbles between mr blair and mr brown were not perceived as problem by the adding there was no impression of governmental cook argued that more prominence was given to these matters because there was not an alternative source of opposition to the spokesman said it was highly unlikely he would give labour more although he would remain supporter and not fund the broadside came as secretary robin cook said he hoped mr brown would be premier at some reported feud between tony blair and gordon brown has prompted labour donor to say he will almost certainly refuse to give more bannatyne also attacked the government over iraq and its poor response to the asian tsunami',\n",
              " 'medical research council professor nancy rothwell said ms kelly views mattered as she was responsible for training future kelly has not set out her detailed views on either issue but has said she intends to put parents first in education was down to the higher education funding council and the research councils to decide on research who is is reported to be and has opposed embryo have also been raised by organisations that ms kelly views might affect sex education policy in if someone as senior as ruth kelly is not going to favour stem cell research we will end up with similarly schizophrenic system in this who is also of research at manchester told the times higher education supplement it would worry her great deal if ministers were have expressed concerns that new education secretary ruth kelly religious views could hamper vital scientific spokeswoman it is not news that ms kelly is catholic but we are not going into any details on she added that claims ms kelly was in charge of university research budget were not',\n",
              " 'he said tory plans to cut tax would cut deep into public will be the central dividing line at the between conservative party taking britain back and planning deep cuts of in our and labour government taking britain which on platform of stability will reform and renew our schools and public services am proud to spend by chancellor said the vote expected to fall on may will give clear and fundamental choice between labour investment and conservative said after seven years labour had transformed from party not trusted with the economy to the only party trusted with the was now party not just of but of employers and he packed audience at gateshead sage the chancellor said the cuts proposed by shadow chancellor oliver letwin were the equivalent of sacking every gp and nurse in the he told',\n",
              " 'mr blair said that whether the public chose michael howard or mr it would result in tory government not labour government and country that goes back and does not move liam fox was speaking after mr blair told labour members the tories offered hard right fox refused to discuss weekend newspaper reports that the party had repaid to former tory treasurer lord ashcroft after he said the party could not win the lib dems accuse mr blair of making speech to labour delegates which will not help him regain public tory attacked labour six new pledges as vacuous and said mr blair was very worried voters would take revenge for his failure to fox accused mr blair and other cabinet ministers of telling lies about their policies and then attacking the what was seen as highly personal speech in gateshead on mr blair have the same passion and hunger as when first walked through the door of downing lib dem leader charles kennedy is expected to attack mr blair words as he begins nationwide tour on would not discuss reports the party repaid to lord ashcroft after he predicted an election',\n",
              " 'six government units would also be scrapped under proposals which the tories say would save more than frontbencher john redwood said britain needed slimmer government and lower taxes to be government has announced plans to cut civil servants as part of its efficiency conservatives are committed to cutting labour public spending plans by massive he tories say the strategic health authorities are not needed as it is better that local rather than run hospitals and to abolish quangos have been unveiled by the conservatives as part of their effort to show how government red tape can be liberal democrats have said they would cut the number of whitehall departments to make sure money reaches frontline are creating two the britain of the forgotten majority and bureaucratic he']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NboVpzGj8U-O"
      },
      "source": [
        "Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Eddc0AYrQBiA",
        "outputId": "d6515049-ddd7-43d1-b79d-483faf36fb6f"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "text_word_count = []\r\n",
        "summary_word_count = []\r\n",
        "\r\n",
        "# populate the lists with sentence lengths\r\n",
        "for i in data['cleaned_text']:\r\n",
        "      text_word_count.append(len(i.split()))\r\n",
        "\r\n",
        "for i in data['cleaned_summary']:\r\n",
        "      summary_word_count.append(len(i.split()))\r\n",
        "\r\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\r\n",
        "\r\n",
        "length_df.hist(bins = 30)\r\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qqYFWjoSJJ8",
        "outputId": "2b9065ee-64dd-4e73-ac96-c159c8499fd8"
      },
      "source": [
        "cnt=0\r\n",
        "for i in data['cleaned_summary']:\r\n",
        "    if(len(i.split())<=200):\r\n",
        "        cnt=cnt+1\r\n",
        "print(cnt/len(data['cleaned_summary']))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8489887640449438\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7kgERuHSkPT",
        "outputId": "9e98f7ec-caad-4c50-daf3-9f95baccfa98"
      },
      "source": [
        "cnt=0\r\n",
        "for i in data['cleaned_text']:\r\n",
        "    if(len(i.split())<=300):\r\n",
        "        cnt=cnt+1\r\n",
        "print(cnt/len(data['cleaned_text']))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9397752808988764\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyRg9nPwSYm8"
      },
      "source": [
        "max_text_len=300\r\n",
        "max_summary_len=200"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4YiHFRuTJPb"
      },
      "source": [
        "cleaned_text =np.array(data['cleaned_text'])\r\n",
        "cleaned_summary=np.array(data['cleaned_summary'])\r\n",
        "\r\n",
        "short_text=[]\r\n",
        "short_summary=[]\r\n",
        "\r\n",
        "for i in range(len(cleaned_text)):\r\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\r\n",
        "        short_text.append(cleaned_text[i])\r\n",
        "        short_summary.append(cleaned_summary[i])\r\n",
        "        \r\n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSi22gV8-0PR"
      },
      "source": [
        "Adding START and END Tokens to the Summary "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHEknacpTOub"
      },
      "source": [
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhU718Dj9Bu"
      },
      "source": [
        "pd.set_option(\"display.max_colwidth\", 1500)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XryXhyF9-9B4"
      },
      "source": [
        "Test Train Split "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZqTuzLATdvH"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mUWzi4oTk2x"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer \r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "#prepare a tokenizer for reviews on training data\r\n",
        "x_tokenizer = Tokenizer() \r\n",
        "x_tokenizer.fit_on_texts(list(x_tr))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qY_JQnK_BQO"
      },
      "source": [
        "Rare words "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV7mCVWuTuoS",
        "outputId": "76731c65-dbbc-4922-a3d2-abb360c124dd"
      },
      "source": [
        "thresh=4\r\n",
        "\r\n",
        "cnt=0\r\n",
        "tot_cnt=0\r\n",
        "freq=0\r\n",
        "tot_freq=0\r\n",
        "\r\n",
        "for key,value in x_tokenizer.word_counts.items():\r\n",
        "    tot_cnt=tot_cnt+1\r\n",
        "    tot_freq=tot_freq+value\r\n",
        "    if(value<thresh):\r\n",
        "        cnt=cnt+1\r\n",
        "        freq=freq+value\r\n",
        "    \r\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\r\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 43.38055920435354\n",
            "Total Coverage of rare words: 3.811186050828616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNmGKdeTT5RM"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\r\n",
        "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \r\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\r\n",
        "\r\n",
        "#convert text sequences into integer sequences\r\n",
        "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \r\n",
        "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\r\n",
        "\r\n",
        "#padding zero upto maximum length\r\n",
        "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\r\n",
        "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\r\n",
        "\r\n",
        "#size of vocabulary ( +1 for padding token)\r\n",
        "x_voc   =  x_tokenizer.num_words + 1"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVil1ccmUBDD",
        "outputId": "2c6c5c20-003c-4daa-fc3c-7fa2afe0df21"
      },
      "source": [
        "x_voc"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12070"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A52ECiZCUHE-"
      },
      "source": [
        "#prepare a tokenizer for summaries on training data\r\n",
        "y_tokenizer = Tokenizer()   \r\n",
        "y_tokenizer.fit_on_texts(list(y_tr))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CtbnzyEUONs",
        "outputId": "6b47e499-6441-4f0f-9c9c-09b3eb629a85"
      },
      "source": [
        "\r\n",
        "thresh=6\r\n",
        "\r\n",
        "cnt=0\r\n",
        "tot_cnt=0\r\n",
        "freq=0\r\n",
        "tot_freq=0\r\n",
        "\r\n",
        "for key,value in y_tokenizer.word_counts.items():\r\n",
        "    tot_cnt=tot_cnt+1\r\n",
        "    tot_freq=tot_freq+value\r\n",
        "    if(value<thresh):\r\n",
        "        cnt=cnt+1\r\n",
        "        freq=freq+value\r\n",
        "    \r\n",
        "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\r\n",
        "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "% of rare words in vocabulary: 58.055877243775335\n",
            "Total Coverage of rare words: 5.239545860971908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhgJuGTMUVDp"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\r\n",
        "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \r\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\r\n",
        "\r\n",
        "#convert text sequences into integer sequences\r\n",
        "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \r\n",
        "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \r\n",
        "\r\n",
        "#padding zero upto maximum length\r\n",
        "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\r\n",
        "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\r\n",
        "\r\n",
        "#size of vocabulary\r\n",
        "y_voc  =   y_tokenizer.num_words +1"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmGESOeJvZ0z",
        "outputId": "6d021747-4165-47d5-e4cc-fff100b8c98a"
      },
      "source": [
        "y_tr.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3396, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roUZxc3dUcqV",
        "outputId": "6821ed85-073c-453b-94b4-ce6c217c7955"
      },
      "source": [
        "y_tokenizer.word_counts['sostok'],len(y_tr)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3396, 3396)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-xrrVomjVkD",
        "outputId": "4d4519a2-4144-467f-f706-776682a7ef88"
      },
      "source": [
        "y_tokenizer.word_counts['eostok'],len(y_tr)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3396, 3396)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qYc3Td5UsP8"
      },
      "source": [
        "ind=[]\r\n",
        "for i in range(len(y_tr)):\r\n",
        "    cnt=0\r\n",
        "    for j in y_tr[i]:\r\n",
        "        if j!=0:\r\n",
        "            cnt=cnt+1\r\n",
        "    if(cnt==2):\r\n",
        "        ind.append(i)\r\n",
        "\r\n",
        "y_tr=np.delete(y_tr,ind, axis=0)\r\n",
        "x_tr=np.delete(x_tr,ind, axis=0)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aig2yIXsUyCj"
      },
      "source": [
        "ind=[]\r\n",
        "for i in range(len(y_val)):\r\n",
        "    cnt=0\r\n",
        "    for j in y_val[i]:\r\n",
        "        if j!=0:\r\n",
        "            cnt=cnt+1\r\n",
        "    if(cnt==2):\r\n",
        "        ind.append(i)\r\n",
        "\r\n",
        "y_val=np.delete(y_val,ind, axis=0)\r\n",
        "x_val=np.delete(x_val,ind, axis=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZEoPeovjK5L",
        "outputId": "17f13d45-56c2-49c0-f68d-7f6ab259c8d2"
      },
      "source": [
        "cnt = 0\r\n",
        "for i in range(len(y_tr)):\r\n",
        "  for j in y_tr[i]:\r\n",
        "    if j==14:      # check that all training data has eostok\r\n",
        "      cnt=cnt+1\r\n",
        "  \r\n",
        "print(cnt)\r\n",
        "print(len(y_tr))\r\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3396\n",
            "3396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jdyU_I6y1Hs",
        "outputId": "a3ebbf4b-3399-4821-e9bc-49de42785e2a"
      },
      "source": [
        "cnt = 0\r\n",
        "for i in range(len(y_val)):\r\n",
        "  for j in y_val[i]:\r\n",
        "    if j==14:      # check that all validation data has eostok\r\n",
        "      cnt=cnt+1\r\n",
        "  \r\n",
        "print(cnt)\r\n",
        "print(len(y_val))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "378\n",
            "378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e61NtD8WVNBa"
      },
      "source": [
        "latent_dim = 300\r\n",
        "embedding_dim=100"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM98n1IUP-pq"
      },
      "source": [
        "Bidiectional LSTM Model with three layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSkNSpSAP8U6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5d5000b-7aa7-444b-bedf-c0c315d5dd47"
      },
      "source": [
        "# Encoder\r\n",
        "encoder_inputs = Input(shape=(max_text_len,))\r\n",
        "\r\n",
        "#embedding layer\r\n",
        "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\r\n",
        "\r\n",
        "#encoder lstm 1\r\n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4,go_backwards=True)\r\n",
        "encoder_output1,  backward_h1 , backward_c1 = encoder_lstm1(enc_emb)\r\n",
        "\r\n",
        "#encoder lstm 2\r\n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4,go_backwards=True)\r\n",
        "encoder_output2,  backward_h2 , backward_c2 = encoder_lstm2(encoder_output1)\r\n",
        "\r\n",
        "#encoder lstm 3\r\n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4,go_backwards=True)\r\n",
        "encoder_outputs,  state_h , state_c= encoder_lstm3(encoder_output2)\r\n",
        "\r\n",
        "#state_h = Concatenate()([forward_h, backward_h])\r\n",
        "#state_c = Concatenate()([forward_c, backward_c])\r\n",
        "\r\n",
        "# Set up the decoder, using `encoder_states` as initial state.\r\n",
        "decoder_inputs = Input(shape=(None,))\r\n",
        "\r\n",
        "#embedding layer\r\n",
        "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\r\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\r\n",
        "\r\n",
        "decoder_lstm = LSTM(latent_dim , return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\r\n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\r\n",
        "\r\n",
        "# Attention layer\r\n",
        "#attn_layer = Attention(name='attention_layer')\r\n",
        "#attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\r\n",
        "\r\n",
        "# Concat attention input and decoder LSTM output\r\n",
        "#decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\r\n",
        "\r\n",
        "#dense layer\r\n",
        "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\r\n",
        "#decoder_outputs = decoder_dense(decoder_concat_input)\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "# Define the model \r\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 300)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 300, 100)     1207000     input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_5 (LSTM)                   [(None, 300, 300), ( 481200      embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_6 (LSTM)                   [(None, 300, 300), ( 721200      lstm_5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, None, 100)    579600      input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_7 (LSTM)                   [(None, 300, 300), ( 721200      lstm_6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, None, 300),  481200      embedding_4[0][0]                \n",
            "                                                                 lstm_7[0][1]                     \n",
            "                                                                 lstm_7[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 5796)   1744596     lstm_8[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,935,996\n",
            "Trainable params: 5,935,996\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp8fobh0VUpP"
      },
      "source": [
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0yFEf2YVZXY"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM8O8f-OVdzy",
        "outputId": "dae2ad69-742e-4e25-8eed-df29fa6f0113"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,\r\n",
        "                   epochs=50,callbacks=[es],batch_size=64, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "54/54 [==============================] - 238s 4s/step - loss: 3.9033 - val_loss: 3.6999\n",
            "Epoch 2/50\n",
            "54/54 [==============================] - 239s 4s/step - loss: 3.6880 - val_loss: 3.4192\n",
            "Epoch 3/50\n",
            "54/54 [==============================] - 241s 4s/step - loss: 3.5327 - val_loss: 3.3721\n",
            "Epoch 4/50\n",
            "54/54 [==============================] - 238s 4s/step - loss: 3.4882 - val_loss: 3.3273\n",
            "Epoch 5/50\n",
            "54/54 [==============================] - 240s 4s/step - loss: 3.4372 - val_loss: 3.2892\n",
            "Epoch 6/50\n",
            "54/54 [==============================] - 239s 4s/step - loss: 3.3994 - val_loss: 3.2645\n",
            "Epoch 7/50\n",
            "54/54 [==============================] - 238s 4s/step - loss: 3.3686 - val_loss: 3.2400\n",
            "Epoch 8/50\n",
            "54/54 [==============================] - 232s 4s/step - loss: 3.3393 - val_loss: 3.2172\n",
            "Epoch 9/50\n",
            "54/54 [==============================] - 231s 4s/step - loss: 3.3112 - val_loss: 3.1914\n",
            "Epoch 10/50\n",
            "54/54 [==============================] - 230s 4s/step - loss: 3.2805 - val_loss: 3.1632\n",
            "Epoch 11/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 3.2457 - val_loss: 3.1360\n",
            "Epoch 12/50\n",
            "54/54 [==============================] - 226s 4s/step - loss: 3.2134 - val_loss: 3.1104\n",
            "Epoch 13/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 3.1825 - val_loss: 3.0856\n",
            "Epoch 14/50\n",
            "54/54 [==============================] - 225s 4s/step - loss: 3.1528 - val_loss: 3.0630\n",
            "Epoch 15/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 3.1228 - val_loss: 3.0397\n",
            "Epoch 16/50\n",
            "54/54 [==============================] - 227s 4s/step - loss: 3.0928 - val_loss: 3.0177\n",
            "Epoch 17/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 3.0640 - val_loss: 2.9959\n",
            "Epoch 18/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 3.0346 - val_loss: 2.9727\n",
            "Epoch 19/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 3.0069 - val_loss: 2.9561\n",
            "Epoch 20/50\n",
            "54/54 [==============================] - 226s 4s/step - loss: 2.9803 - val_loss: 2.9341\n",
            "Epoch 21/50\n",
            "54/54 [==============================] - 226s 4s/step - loss: 2.9537 - val_loss: 2.9153\n",
            "Epoch 22/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.9285 - val_loss: 2.8949\n",
            "Epoch 23/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.9033 - val_loss: 2.8761\n",
            "Epoch 24/50\n",
            "54/54 [==============================] - 226s 4s/step - loss: 2.8768 - val_loss: 2.8577\n",
            "Epoch 25/50\n",
            "54/54 [==============================] - 227s 4s/step - loss: 2.8529 - val_loss: 2.8396\n",
            "Epoch 26/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.8280 - val_loss: 2.8220\n",
            "Epoch 27/50\n",
            "54/54 [==============================] - 235s 4s/step - loss: 2.8045 - val_loss: 2.8089\n",
            "Epoch 28/50\n",
            "54/54 [==============================] - 233s 4s/step - loss: 2.7823 - val_loss: 2.7886\n",
            "Epoch 29/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.7588 - val_loss: 2.7748\n",
            "Epoch 30/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.7370 - val_loss: 2.7610\n",
            "Epoch 31/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.7161 - val_loss: 2.7468\n",
            "Epoch 32/50\n",
            "54/54 [==============================] - 230s 4s/step - loss: 2.6970 - val_loss: 2.7409\n",
            "Epoch 33/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.6821 - val_loss: 2.7208\n",
            "Epoch 34/50\n",
            "54/54 [==============================] - 232s 4s/step - loss: 2.6572 - val_loss: 2.7073\n",
            "Epoch 35/50\n",
            "54/54 [==============================] - 237s 4s/step - loss: 2.6382 - val_loss: 2.6959\n",
            "Epoch 36/50\n",
            "54/54 [==============================] - 240s 4s/step - loss: 2.6187 - val_loss: 2.6835\n",
            "Epoch 37/50\n",
            "54/54 [==============================] - 240s 4s/step - loss: 2.6000 - val_loss: 2.6722\n",
            "Epoch 38/50\n",
            "54/54 [==============================] - 239s 4s/step - loss: 2.5820 - val_loss: 2.6601\n",
            "Epoch 39/50\n",
            "54/54 [==============================] - 236s 4s/step - loss: 2.5661 - val_loss: 2.6501\n",
            "Epoch 40/50\n",
            "54/54 [==============================] - 231s 4s/step - loss: 2.5488 - val_loss: 2.6393\n",
            "Epoch 41/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.5298 - val_loss: 2.6298\n",
            "Epoch 42/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.5138 - val_loss: 2.6188\n",
            "Epoch 43/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.4965 - val_loss: 2.6077\n",
            "Epoch 44/50\n",
            "54/54 [==============================] - 226s 4s/step - loss: 2.4798 - val_loss: 2.5985\n",
            "Epoch 45/50\n",
            "54/54 [==============================] - 231s 4s/step - loss: 2.4636 - val_loss: 2.5881\n",
            "Epoch 46/50\n",
            "54/54 [==============================] - 228s 4s/step - loss: 2.4476 - val_loss: 2.5793\n",
            "Epoch 47/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.4329 - val_loss: 2.5698\n",
            "Epoch 48/50\n",
            "54/54 [==============================] - 229s 4s/step - loss: 2.4163 - val_loss: 2.5614\n",
            "Epoch 49/50\n",
            "54/54 [==============================] - 225s 4s/step - loss: 2.4007 - val_loss: 2.5509\n",
            "Epoch 50/50\n",
            "54/54 [==============================] - 232s 4s/step - loss: 2.3855 - val_loss: 2.5424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv60rPdAevt2"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word\r\n",
        "reverse_source_word_index=x_tokenizer.index_word\r\n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T0Q6B44n2C0"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaxI7Yd3n4zz"
      },
      "source": [
        "#acc = history.history['accuracy']\r\n",
        "#val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXgDK-bOn8KL"
      },
      "source": [
        "epochs = range(1,len(loss)+1)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDwpMWtZoACr"
      },
      "source": [
        "#plt.plot(epochs , acc , 'bo' ,  label = 'Training acc')\r\n",
        "#plt.plot(epochs , val_acc , 'b' ,  label = 'Validation acc')\r\n",
        "#plt.title('Training and Validation accuracy')\r\n",
        "#plt.legend()\r\n",
        "#plt.figure()"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlePCCzRoEIG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "495efba4-5ece-4ed1-869c-761dc79fe6bb"
      },
      "source": [
        "plt.plot(epochs , loss , 'bo' ,  label = 'Training loss')\r\n",
        "plt.plot(epochs , val_loss , 'b' ,  label = 'Validation loss')\r\n",
        "plt.title('Training and Validation loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XVp3knXUuVR"
      },
      "source": [
        "\r\n",
        "# Encode the input sequence to get the feature vector\r\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\r\n",
        "\r\n",
        "# Decoder setup\r\n",
        "# Below tensors will hold the states of the previous time step\r\n",
        "decoder_state_input_h = Input(shape=(latent_dim ,))\r\n",
        "decoder_state_input_c = Input(shape=(latent_dim ,))\r\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\r\n",
        "\r\n",
        "# Get the embeddings of the decoder sequence\r\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) \r\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\r\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\r\n",
        "\r\n",
        "#attention inference\r\n",
        "#attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\r\n",
        "#decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\r\n",
        "\r\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\r\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \r\n",
        "\r\n",
        "# Final decoder model\r\n",
        "decoder_model = Model(\r\n",
        "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\r\n",
        "    [decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNiMte-wvEYN"
      },
      "source": [
        "\r\n",
        "# define inference encoder\r\n",
        "#encoder_model = Model(encoder_inputs, encoder_states)\r\n",
        "# define inference decoder\r\n",
        "#decoder_state_input_h = Input(shape=(n_units*2,))\r\n",
        "#decoder_state_input_c = Input(shape=(n_units*2,))\r\n",
        "#decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "#decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\r\n",
        "#decoder_states = [state_h, state_c]\r\n",
        "#decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "#decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DelLQPGMfRVj"
      },
      "source": [
        "def decode_sequence_LSTM(input_seq):\r\n",
        "    # Encode the input as state vectors.\r\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\r\n",
        "    \r\n",
        "    # Generate empty target sequence of length 1.\r\n",
        "    target_seq = np.zeros((1,1))\r\n",
        "    \r\n",
        "    # Populate the first word of target sequence with the start word.\r\n",
        "    target_seq[0, 0] = target_word_index['sostok']\r\n",
        "\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = ''\r\n",
        "    while not stop_condition:\r\n",
        "      \r\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\r\n",
        "        \r\n",
        "        # Sample a token\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1,2 :]) + 2\r\n",
        "        if(sampled_token_index == 0):\r\n",
        "          print('sample token index',sampled_token_index)\r\n",
        "        if(sampled_token_index == 0):\r\n",
        "          next\r\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\r\n",
        "        \r\n",
        "        if(sampled_token!='eostok'):\r\n",
        "            decoded_sentence += ' '+sampled_token\r\n",
        "\r\n",
        "        # Exit condition: either hit max length or find stop word.\r\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\r\n",
        "            stop_condition = True\r\n",
        "\r\n",
        "        # Update the target sequence (of length 1).\r\n",
        "        target_seq = np.zeros((1,1))\r\n",
        "        target_seq[0, 0] = sampled_token_index\r\n",
        "\r\n",
        "        # Update internal states\r\n",
        "        e_h, e_c = h, c\r\n",
        "\r\n",
        "    return decoded_sentence"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFObaniRfYXz"
      },
      "source": [
        "def seq2summary(input_seq):\r\n",
        "    newString=''\r\n",
        "    for i in input_seq:\r\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\r\n",
        "            newString=newString+reverse_target_word_index[i]+' '\r\n",
        "    return newString\r\n",
        "\r\n",
        "def seq2text(input_seq):\r\n",
        "    newString=''\r\n",
        "    for i in input_seq:\r\n",
        "        if(i!=0):\r\n",
        "            newString=newString+reverse_source_word_index[i]+' '\r\n",
        "    return newString"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p_yyjHVfeCw",
        "outputId": "61445ed3-d56e-4b64-953f-8bcead2e8b0e"
      },
      "source": [
        "for i in range(4,5):\r\n",
        "    print(\"Review:\",seq2text(x_val[i]))\r\n",
        "    manual_summary = seq2summary(y_val[i])\r\n",
        "    print(\"Original summary:\",manual_summary)\r\n",
        "    output = decode_sequence_LSTM(x_val[i].reshape(1,max_text_len))\r\n",
        "    print(\"Predicted summary:\",output)\r\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: laws bite spammer net spam king seeking bankruptcy man behind billions junk mail said lawsuits forced company chapter optinrealbig fighting several legal notably pushing millions dollars company said filing chapter would help try resolve legal problems still keep third biggest spammer world junk mail watchdog optinrealbig sued december sending mail messages violated lawsuit brought microsoft new york attorney general eliot spitzer alleged mr sent billions spam messages compromised net addresses according microsoft messages sent via net addresses owned ministries communication several korean virginia community college mr settled attorney general case july legal fight microsoft microsoft seeking millions dollars damages optinrealbig laws impose penalties every statement announcing desire seek bankruptcy protection company said could continue contend legal debts included microsoft seeking via litigation relentless distraction said steven legal counsel make expect part optinrealbig describes premier internet marketing company said move seek chapter necessary let keep trading legal \n",
            "Original summary: was fighting several legal most against which is pushing for millions of dollars in its part describes itself as premier internet marketing company and said the move to seek chapter was necessary to let it keep trading while out its legal its chapter filing claimed it had assets of less than by number of companies across the including and still run lawsuit was brought by microsoft and new york attorney general spitzer who alleged that mr and his sent billions of spam messages through net addresses in has been with which to said steven legal for \n",
            "Predicted summary:  mr blair said he was not to be an election for mr blair said he was not to be able to be able to be able to be in response to soften up opinion in and asylum said he was not to be said he was speaking to be in charge of his own he said he was unaware of conspiracy to be to vote in and mr blair said he was not to be for his party and mr kennedy said he was not to be prime minister and mr howard said he was not to be prime minister and mr howard said he was not to be for granted in\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGNLj-ooTJP"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\r\n",
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwYIBjahoV6m"
      },
      "source": [
        "candidate = output.strip().split()\r\n",
        "reference=manual_summary.strip().split()"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtIz32Floai7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f070035b-9851-4ade-b42e-f9d43352421a"
      },
      "source": [
        "score = sentence_bleu([reference], candidate)\r\n",
        "print(score)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6500593260343692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzNEKUbjoeDP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e7dd381-c7eb-4e1f-b8c9-d931c19ea332"
      },
      "source": [
        "score = corpus_bleu([[reference]],[candidate])\r\n",
        "print(score)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6500593260343692\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn_Llnt-ojUt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c4ef92-7f0a-4749-8820-47bfd73439f6"
      },
      "source": [
        "!pip install rouge"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rouge in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rouge) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L4o-k_XomZ0"
      },
      "source": [
        "from rouge import Rouge\r\n",
        "r = Rouge()"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmljOPvloqYs"
      },
      "source": [
        "scores = r.get_scores([manual_summary],[output])"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2jkVbWdot-j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ccc8a24-185d-4edb-d2a8-1e639bd94159"
      },
      "source": [
        "print(scores)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[{'rouge-1': {'f': 0.19230768733727824, 'p': 0.20833333333333334, 'r': 0.17857142857142858}, 'rouge-2': {'f': 0.0, 'p': 0.0, 'r': 0.0}, 'rouge-l': {'f': 0.14953270601449922, 'p': 0.10810810810810811, 'r': 0.24242424242424243}}]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}